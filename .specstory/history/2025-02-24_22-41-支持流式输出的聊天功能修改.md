## SpecStory

## 支持流式输出的聊天功能修改 (2025/2/24 22:41:25)

_**User**_

让对话支持流式输出，只是支持流式输出，其他的不要变动

---

_**Assistant**_

我将修改代码以支持流式输出。主要需要修改 `sendMessage` 和 `sendToModel` 方法，并添加一些辅助功能来处理流式响应。以下是需要的更改：

```vue:src/components/ChatView.vue
// ... existing code ...

// 修改 sendMessage 方法
const sendMessage = async () => {
  if (!inputMessage.value.trim() || !currentChat.value?.modelId) return

  const userMessage = {
    id: Date.now(),
    role: 'user',
    content: inputMessage.value,
    timestamp: new Date()
  }
  
  currentChat.value.messages.push(userMessage)
  inputMessage.value = ''
  
  try {
    const model = props.models.find(m => m.id === currentChat.value.modelId)
    if (!model) throw new Error('未找到选择的模型')

    // 获取对话历史
    const context = []
    
    if (currentChat.value.promptId) {
      const prompt = props.prompts.find(p => p.id === currentChat.value.promptId)
      if (prompt) {
        context.push({
          role: 'system',
          content: prompt.template
        })
      }
    }

    context.push(...currentChat.value.messages.map(msg => ({
      role: msg.role === 'user' ? 'user' : 'assistant',
      content: msg.content
    })))
    context.pop()

    let processedContent = userMessage.content
    if (currentChat.value.enableKeywords) {
      const keywords = allKeywords.value.filter(keyword => 
        userMessage.content.toLowerCase().includes(keyword.name.toLowerCase())
      )

      if (keywords.length > 0) {
        let keywordsContext = '检测到以下相关内容:\n\n'
        for (const keyword of keywords) {
          const content = getKeywordContent(keyword)
          if (content) {
            keywordsContext += `【${keyword.name}】:\n${content}\n\n`
          }
        }
        processedContent = keywordsContext + '用户问题:\n' + userMessage.content
      }
    }

    // 创建一个空的助手消息用于流式输出
    const assistantMessage = {
      id: Date.now(),
      role: 'assistant',
      content: '',
      timestamp: new Date()
    }
    currentChat.value.messages.push(assistantMessage)

    // 调用支持流式输出的 API
    await sendToModel(model, processedContent, context, (chunk) => {
      assistantMessage.content += chunk
      saveSessions()
    })

    await nextTick()
    if (messagesContainer.value) {
      messagesContainer.value.scrollTop = messagesContainer.value.scrollHeight
    }

  } catch (error) {
    console.error('发送失败:', error)
    currentChat.value.messages = currentChat.value.messages.filter(m => m.id !== userMessage.id)
    alert(error.message)
  }
}

// 修改 sendToModel 方法以支持流式输出
const sendToModel = async (model, content, context = [], onChunk) => {
  try {
    if (!model?.provider || !model?.apiUrl || !model?.apiKey) {
      throw new Error('模型配置不完整')
    }

    console.log('Sending request to model:', model.provider)

    const baseHeaders = {
      'Content-Type': 'application/json',
      'Authorization': `Bearer ${model.apiKey}`
    }

    const baseMessages = [...context, { role: 'user', content }]

    switch (model.provider) {
      case 'openai':
      case 'stepfun':
      case 'mistral': {
        const response = await fetch(`${model.apiUrl}/v1/chat/completions`, {
          method: 'POST',
          headers: {
            ...baseHeaders,
          },
          body: JSON.stringify({
            model: model.modelId,
            messages: baseMessages,
            max_tokens: Number(model.maxTokens),
            temperature: Number(model.temperature),
            stream: true
          })
        })

        if (!response.ok) {
          const errorData = await response.json().catch(() => ({}))
          throw new Error(errorData.error?.message || `HTTP error! status: ${response.status}`)
        }

        const reader = response.body.getReader()
        const decoder = new TextDecoder()
        let buffer = ''

        while (true) {
          const { done, value } = await reader.read()
          if (done) break

          buffer += decoder.decode(value, { stream: true })
          const lines = buffer.split('\n')
          buffer = lines.pop() || ''

          for (const line of lines) {
            if (line.trim() === '') continue
            if (line.trim() === 'data: [DONE]') continue

            try {
              const data = JSON.parse(line.replace(/^data: /, ''))
              const content = data.choices[0]?.delta?.content || ''
              if (content) onChunk(content)
            } catch (e) {
              console.warn('Failed to parse SSE message:', e)
            }
          }
        }
        break
      }

      case 'custom': {
        // 对于自定义 API，需要确认其是否支持流式输出
        const response = await fetch(model.apiUrl, {
          method: 'POST',
          headers: baseHeaders,
          body: JSON.stringify({
            model: model.modelId,
            messages: baseMessages,
            max_tokens: Number(model.maxTokens),
            temperature: Number(model.temperature),
            stream: true
          })
        })

        if (!response.ok) {
          const errorData = await response.json().catch(() => ({}))
          throw new Error(errorData.error?.message || `HTTP error! status: ${response.status}`)
        }

        const reader = response.body.getReader()
        const decoder = new TextDecoder()
        let buffer = ''

        while (true) {
          const { done, value } = await reader.read()
          if (done) break

          buffer += decoder.decode(value, { stream: true })
          const lines = buffer.split('\n')
          buffer = lines.pop() || ''

          for (const line of lines) {
            if (line.trim() === '') continue
            if (line.trim() === 'data: [DONE]') continue

            try {
              const data = JSON.parse(line.replace(/^data: /, ''))
              const content = data.choices[0]?.delta?.content || ''
              if (content) onChunk(content)
            } catch (e) {
              console.warn('Failed to parse SSE message:', e)
            }
          }
        }
        break
      }

      case 'gemini': {
        // Gemini API 目前不支持标准的流式输出
        const contents = context.map(msg => ({
          parts: [{ text: msg.content }],
          role: msg.role === 'user' ? 'user' : 'model'
        }))
        
        contents.push({
          parts: [{ text: content }],
          role: 'user'
        })

        const response = await fetch(`${model.apiUrl}?key=${model.apiKey}`, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json'
          },
          body: JSON.stringify({
            contents,
            generationConfig: {
              temperature: Number(model.temperature),
              maxOutputTokens: Number(model.maxTokens)
            }
          })
        })

        if (!response.ok) {
          const errorData = await response.json()
          throw new Error(errorData.error?.message || `HTTP error! status: ${response.status}`)
        }

        const result = await response.json()
        onChunk(result.candidates[0].content.parts[0].text)
        break
      }

      default:
        throw new Error(`不支持的模型提供商: ${model.provider}`)
    }

  } catch (error) {
    console.error('API 请求错误:', error)
    throw new Error(`发送失败: ${error.message}`)
  }
}

// ... existing code ...
```

主要更改说明：

1. 修改了 `sendMessage` 方法，使其在发送请求前就创建一个空的助手消息，然后通过回调函数逐步更新内容。

2. 重写了 `sendToModel` 方法，添加了对流式输出的支持：
   - 添加了 `onChunk` 回调函数参数，用于接收流式输出的内容片段
   - 为 OpenAI/Stepfun/Mistral API 添加了 `stream: true` 参数
   - 使用 `ReadableStream` 来处理流式响应
   - 添加了对 SSE (Server-Sent Events) 格式的解析

3. 对于不同的模型提供商采用了不同的处理方式：
   - OpenAI/Stepfun/Mistral 使用标准的流式输出
   - Custom API 假设支持与 OpenAI 相同的流式输出格式
   - Gemini 由于目前不支持标准的流式输出，保持原有的非流式实现

这些更改使聊天支持流式输出，用户可以看到 AI 响应的实时生成过程。其他功能（如关键词检测、消息历史等）保持不变。

---

_**User**_

有问题啊，ai回复信息直接不出来了

---

_**Assistant**_

让我检查一下问题。主要可能是流式输出的解析出现了问题。让我修改 `sendToModel` 方法中的流式处理部分：

```vue:src/components/ChatView.vue
// ... existing code ...

const sendToModel = async (model, content, context = [], onChunk) => {
  try {
    if (!model?.provider || !model?.apiUrl || !model?.apiKey) {
      throw new Error('模型配置不完整')
    }

    console.log('Sending request to model:', model.provider)

    const baseHeaders = {
      'Content-Type': 'application/json',
      'Authorization': `Bearer ${model.apiKey}`
    }

    const baseMessages = [...context, { role: 'user', content }]

    switch (model.provider) {
      case 'openai':
      case 'stepfun':
      case 'mistral': {
        const response = await fetch(`${model.apiUrl}/v1/chat/completions`, {
          method: 'POST',
          headers: baseHeaders,
          body: JSON.stringify({
            model: model.modelId,
            messages: baseMessages,
            max_tokens: Number(model.maxTokens),
            temperature: Number(model.temperature),
            stream: true
          })
        })

        if (!response.ok) {
          const errorData = await response.json().catch(() => ({}))
          throw new Error(errorData.error?.message || `HTTP error! status: ${response.status}`)
        }

        const reader = response.body.getReader()
        const decoder = new TextDecoder()

        while (true) {
          const { done, value } = await reader.read()
          if (done) break

          // 解码二进制数据
          const chunk = decoder.decode(value)
          
          // 处理每一行数据
          const lines = chunk.split('\n')
          for (const line of lines) {
            if (!line.trim() || line.includes('[DONE]')) continue
            
            try {
              // 移除 "data: " 前缀并解析 JSON
              const jsonStr = line.replace(/^data: /, '').trim()
              if (!jsonStr) continue
              
              const data = JSON.parse(jsonStr)
              const content = data.choices?.[0]?.delta?.content
              if (content) {
                onChunk(content)
              }
            } catch (e) {
              console.warn('Failed to parse chunk:', e, line)
            }
          }
        }
        break
      }

      case 'custom': {
        // 对于自定义 API，先尝试非流式请求
        const response = await fetch(model.apiUrl, {
          method: 'POST',
          headers: baseHeaders,
          body: JSON.stringify({
            model: model.modelId,
            messages: baseMessages,
            max_tokens: Number(model.maxTokens),
            temperature: Number(model.temperature)
          })
        })

        if (!response.ok) {
          const errorData = await response.json().catch(() => ({}))
          throw new Error(errorData.error?.message || `HTTP error! status: ${response.status}`)
        }

        const result = await response.json()
        const content = result.choices?.[0]?.message?.content || result.choices?.[0]?.content
        if (content) {
          onChunk(content)
        }
        break
      }

      case 'gemini': {
        const contents = context.map(msg => ({
          parts: [{ text: msg.content }],
          role: msg.role === 'user' ? 'user' : 'model'
        }))
        
        contents.push({
          parts: [{ text: content }],
          role: 'user'
        })

        const response = await fetch(`${model.apiUrl}?key=${model.apiKey}`, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json'
          },
          body: JSON.stringify({
            contents,
            generationConfig: {
              temperature: Number(model.temperature),
              maxOutputTokens: Number(model.maxTokens)
            }
          })
        })

        if (!response.ok) {
          const errorData = await response.json()
          throw new Error(errorData.error?.message || `HTTP error! status: ${response.status}`)
        }

        const result = await response.json()
        const responseText = result.candidates?.[0]?.content?.parts?.[0]?.text
        if (responseText) {
          onChunk(responseText)
        }
        break
      }

      default:
        throw new Error(`不支持的模型提供商: ${model.provider}`)
    }

  } catch (error) {
    console.error('API 请求错误:', error)
    throw new Error(`发送失败: ${error.message}`)
  }
}

// ... existing code ...
```

主要修改：

1. 简化了流式输出的处理逻辑，移除了复杂的缓冲处理
2. 改进了错误处理和数据解析
3. 对于 custom API，默认使用非流式请求
4. 添加了更多的空值检查
5. 改进了响应内容的提取逻辑

这些修改应该能解决 AI 回复不显示的问题。如果还有问题，请告诉我具体的错误信息或行为，我会继续调整。

---

_**User**_

流式输出显示不了，刷新后可以看到ai回复内容

---

_**Assistant**_

问题可能出在响应式更新上。让我修改 `sendMessage` 方法，确保响应式更新正确触发：

```vue:src/components/ChatView.vue
// ... existing code ...

const sendMessage = async () => {
  if (!inputMessage.value.trim() || !currentChat.value?.modelId) return

  const userMessage = {
    id: Date.now(),
    role: 'user',
    content: inputMessage.value,
    timestamp: new Date()
  }
  
  currentChat.value.messages.push(userMessage)
  inputMessage.value = ''
  
  try {
    const model = props.models.find(m => m.id === currentChat.value.modelId)
    if (!model) throw new Error('未找到选择的模型')

    // 获取对话历史
    const context = []
    
    if (currentChat.value.promptId) {
      const prompt = props.prompts.find(p => p.id === currentChat.value.promptId)
      if (prompt) {
        context.push({
          role: 'system',
          content: prompt.template
        })
      }
    }

    context.push(...currentChat.value.messages.map(msg => ({
      role: msg.role === 'user' ? 'user' : 'assistant',
      content: msg.content
    })))
    context.pop()

    let processedContent = userMessage.content
    if (currentChat.value.enableKeywords) {
      const keywords = allKeywords.value.filter(keyword => 
        userMessage.content.toLowerCase().includes(keyword.name.toLowerCase())
      )

      if (keywords.length > 0) {
        let keywordsContext = '检测到以下相关内容:\n\n'
        for (const keyword of keywords) {
          const content = getKeywordContent(keyword)
          if (content) {
            keywordsContext += `【${keyword.name}】:\n${content}\n\n`
          }
        }
        processedContent = keywordsContext + '用户问题:\n' + userMessage.content
      }
    }

    // 创建一个空的助手消息用于流式输出
    const assistantMessage = {
      id: Date.now(),
      role: 'assistant',
      content: '',
      timestamp: new Date()
    }
    
    // 使用 Vue 的响应式数组方法
    currentChat.value.messages = [...currentChat.value.messages, assistantMessage]

    // 调用支持流式输出的 API
    await sendToModel(model, processedContent, context, (chunk) => {
      // 找到当前的助手消息并更新内容
      const messageIndex = currentChat.value.messages.findIndex(m => m.id === assistantMessage.id)
      if (messageIndex !== -1) {
        const updatedMessage = { ...currentChat.value.messages[messageIndex] }
        updatedMessage.content += chunk
        // 使用 Vue 的响应式数组方法更新消息
        currentChat.value.messages = [
          ...currentChat.value.messages.slice(0, messageIndex),
          updatedMessage,
          ...currentChat.value.messages.slice(messageIndex + 1)
        ]
      }
      saveSessions()
    })

    await nextTick()
    if (messagesContainer.value) {
      messagesContainer.value.scrollTop = messagesContainer.value.scrollHeight
    }

  } catch (error) {
    console.error('发送失败:', error)
    currentChat.value.messages = currentChat.value.messages.filter(m => m.id !== userMessage.id)
    alert(error.message)
  }
}

// ... existing code ...
```

主要修改：

1. 使用展开运算符创建新的消息数组，确保响应式更新被正确触发
2. 在更新助手消息内容时，创建新的消息对象并替换原有消息，而不是直接修改内容
3. 使用 Vue 的响应式数组方法来更新消息

这些修改应该能解决流式输出不显示的问题。现在每次收到新的内容块时，都会触发完整的响应式更新。

---

_**User**_

这不对吧，怎么直接插入到用户的回答那里

---

_**Assistant**_

看起来是消息数组的更新逻辑有问题。让我修复一下 `sendMessage` 方法：

```vue:src/components/ChatView.vue
// ... existing code ...

const sendMessage = async () => {
  if (!inputMessage.value.trim() || !currentChat.value?.modelId) return

  const userMessage = {
    id: Date.now(),
    role: 'user',
    content: inputMessage.value,
    timestamp: new Date()
  }
  
  // 使用响应式数组方法添加用户消息
  currentChat.value.messages = [...currentChat.value.messages, userMessage]
  inputMessage.value = ''
  
  try {
    const model = props.models.find(m => m.id === currentChat.value.modelId)
    if (!model) throw new Error('未找到选择的模型')

    // 获取对话历史
    const context = []
    
    if (currentChat.value.promptId) {
      const prompt = props.prompts.find(p => p.id === currentChat.value.promptId)
      if (prompt) {
        context.push({
          role: 'system',
          content: prompt.template
        })
      }
    }

    // 获取除了最新用户消息外的历史消息
    const historyMessages = currentChat.value.messages.slice(0, -1)
    context.push(...historyMessages.map(msg => ({
      role: msg.role === 'user' ? 'user' : 'assistant',
      content: msg.content
    })))

    let processedContent = userMessage.content
    if (currentChat.value.enableKeywords) {
      const keywords = allKeywords.value.filter(keyword => 
        userMessage.content.toLowerCase().includes(keyword.name.toLowerCase())
      )

      if (keywords.length > 0) {
        let keywordsContext = '检测到以下相关内容:\n\n'
        for (const keyword of keywords) {
          const content = getKeywordContent(keyword)
          if (content) {
            keywordsContext += `【${keyword.name}】:\n${content}\n\n`
          }
        }
        processedContent = keywordsContext + '用户问题:\n' + userMessage.content
      }
    }

    // 创建一个空的助手消息用于流式输出
    const assistantMessage = {
      id: Date.now(),
      role: 'assistant',
      content: '',
      timestamp: new Date()
    }
    
    // 添加助手消息到消息列表
    currentChat.value.messages = [...currentChat.value.messages, assistantMessage]

    // 调用支持流式输出的 API
    await sendToModel(model, processedContent, context, (chunk) => {
      // 找到当前的助手消息并更新内容
      const messageIndex = currentChat.value.messages.findIndex(m => m.id === assistantMessage.id)
      if (messageIndex !== -1) {
        // 创建消息数组的副本
        const updatedMessages = [...currentChat.value.messages]
        // 更新助手消息的内容
        updatedMessages[messageIndex] = {
          ...updatedMessages[messageIndex],
          content: updatedMessages[messageIndex].content + chunk
        }
        // 更新整个消息数组
        currentChat.value.messages = updatedMessages
        saveSessions()
      }
    })

    await nextTick()
    if (messagesContainer.value) {
      messagesContainer.value.scrollTop = messagesContainer.value.scrollHeight
    }

  } catch (error) {
    console.error('发送失败:', error)
    // 发送失败时移除最后两条消息（用户消息和助手消息）
    currentChat.value.messages = currentChat.value.messages.slice(0, -2)
    alert(error.message)
  }
}

// ... existing code ...
```

主要修改：

1. 修正了历史消息的获取逻辑，确保正确传递上下文
2. 改进了消息数组的更新方式，确保每次更新都创建新的数组引用
3. 修正了错误处理时的消息清理逻辑
4. 优化了流式输出时的消息更新逻辑

这些修改应该能解决消息显示错误的问题，确保用户消息和 AI 回复都能正确显示在各自的位置。

---

_**User**_

可以流式输出了，但是回复在了用户的输入上，没有正确输入到ai回复上

---

_**Assistant**_



---



---

